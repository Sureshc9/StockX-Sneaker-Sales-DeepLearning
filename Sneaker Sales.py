# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zzqi_3VbKyJOWA5wcSv5XNyzDVKt2cjH
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split

# -----------------------------------------
# âœ… Step 1: Load & Preprocess the Dataset
# -----------------------------------------

file_path = "/content/StockX-Data-Contest-2019-3.csv"

# Load dataset
df = pd.read_csv(file_path, encoding='latin1')

# Rename columns for better readability
df.rename(columns={
    df.columns[0]: 'order_date',
    'Brand': 'brand',
    'Sneaker Name': 'sneaker_name',
    'Sale Price': 'sale_price',
    'Retail Price': 'retail_price',
    'Release Date': 'release_date',
    'Shoe Size': 'shoe_size',
    'Buyer Region': 'buyer_region'
}, inplace=True)

# Convert date columns to datetime format
df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')
df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')

# Convert numeric columns from string to float (handling currency symbols)
df['sale_price'] = df['sale_price'].replace({'\$': '', ',': ''}, regex=True).astype(float)
df['retail_price'] = df['retail_price'].replace({'\$': '', ',': ''}, regex=True).astype(float)
df['shoe_size'] = pd.to_numeric(df['shoe_size'], errors='coerce')

# Drop rows with missing values
df.dropna(inplace=True)

# Remove outliers in sale_price using IQR method
Q1 = df['sale_price'].quantile(0.25)
Q3 = df['sale_price'].quantile(0.75)
IQR = Q3 - Q1
df = df[(df['sale_price'] >= (Q1 - 1.5 * IQR)) & (df['sale_price'] <= (Q3 + 1.5 * IQR))]

"""**Exploratory Data Analysis (EDA)**"""

# ðŸ”¹ Distribution of Sale Prices
plt.figure(figsize=(10,5))
sns.histplot(df['sale_price'], bins=50, kde=True, color="blue")
plt.xlabel("Sale Price")
plt.ylabel("Frequency")
plt.title("Distribution of Sneaker Sale Prices")
plt.show()

# ðŸ”¹ Top-Selling Sneaker Brands
brand_counts = df['brand'].value_counts()
plt.figure(figsize=(12,6))
sns.barplot(x=brand_counts.index[:10], y=brand_counts.values[:10], palette="viridis")
plt.xticks(rotation=45)
plt.xlabel("Brand")
plt.ylabel("Number of Sales")
plt.title("Top 10 Most Selling Sneaker Brands")
plt.show()

# ðŸ”¹ Trend of Sneaker Sales Over Time
df['year_month'] = df['order_date'].dt.to_period('M')
sales_trend = df.groupby('year_month').size()

if not sales_trend.empty:
    plt.figure(figsize=(18,6))
    sales_trend.plot(kind='line', marker='o', color='red')
    plt.xlabel("Year-Month")
    plt.ylabel("Number of Sales")
    plt.title("Trend of Sneaker Sales Over Time")
    plt.xticks(rotation=45)
    plt.grid()
    plt.show()
else:
    print("âŒ No sales data available to plot. Check dataset!")

# ðŸ”¹ Sales Price by Shoe Size
plt.figure(figsize=(18,6))
sns.boxplot(x='shoe_size', y='sale_price', data=df, palette="coolwarm")
plt.xlabel("Shoe Size")
plt.ylabel("Sale Price")
plt.title("Sale Price Distribution by Shoe Size")
plt.show()

# ðŸ”¹ Correlation Matrix
plt.figure(figsize=(16,6))
sns.heatmap(df[['sale_price', 'retail_price', 'shoe_size']].corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Matrix")
plt.show()

"""**Deep Learning Model for Sneaker Brand Prediction**"""

# Encode categorical labels for brands
label_encoder = LabelEncoder()
df['brand_encoded'] = label_encoder.fit_transform(df['brand'])

# Select relevant features and target variable
X = df[['sale_price', 'retail_price', 'shoe_size']]
y = df['brand_encoded']

# Scale numerical features for better model performance
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Build Deep Learning Model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dense(len(label_encoder.classes_), activation='softmax')  # Multi-class classification
])

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32, verbose=1)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"\nâœ… Model Test Accuracy: {accuracy:.2f}")

"""**Prediction - Most Selling Brand**"""

# Predict the most likely brand for a given shoe size and price
sample_input = np.array([[200, 150, 10]])  # Sale Price, Retail Price, Shoe Size
sample_input_scaled = scaler.transform(sample_input)
predicted_brand = label_encoder.inverse_transform([np.argmax(model.predict(sample_input_scaled))])[0]

print(f"\nðŸ”¥ Predicted Most Selling Brand for Given Input: {predicted_brand}")
